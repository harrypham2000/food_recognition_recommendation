{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIGPndyXJMib"
      },
      "source": [
        "Mount Drive and authorize for the use of it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "biqN4SvbJrjT",
        "outputId": "99140774-3a32-4fc4-d033-ae48d28eb5b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i1HBBUcvOX5k",
        "outputId": "8bb2dce9-814d-4185-8c82-f157a91803b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "'nvidia-smi' is not recognized as an internal or external command,\n",
            "operable program or batch file.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "#os.chdir(\"/content/gdrive/Othercomputers/MyLaptop/thesis2024\")\n",
        "%pwd\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "7557thYiH1Ie"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "%matplotlib inline\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras import models\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S, EfficientNetV2L\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd C:\\Users\\Harry\\Desktop\\thesis2024\\data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4s0kwNNAV7A"
      },
      "source": [
        "Load and extract dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6R6XfQxXAVpe"
      },
      "outputs": [],
      "source": [
        "# Helper function to download data and extract\n",
        "\n",
        "def get_data_extract():\n",
        "  if \"food-101\" in os.listdir():\n",
        "    print(\"Dataset already exists\")\n",
        "  else:\n",
        "    print(\"Downloading the data...\")\n",
        "    !wget http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "    print(\"Dataset downloaded!\")\n",
        "    print(\"Extracting data..\")\n",
        "    !tar xzvf food-101.tar.gz\n",
        "    print(\"Extraction done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnFWGaJHAd32",
        "outputId": "9636a5b7-1f8a-45c8-b50b-1fbfd5448240"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset already exists\n"
          ]
        }
      ],
      "source": [
        "# Download data and extract it to folder\n",
        "# Uncomment this below line if you are on Colab\n",
        "get_data_extract()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ckU-Fs6Akbm"
      },
      "source": [
        "Sorting dataset into folders\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "drlJV3a3Aj0F"
      },
      "outputs": [],
      "source": [
        "data_dir='/content/drive/Othercomputers/MyLaptop/thesis2024/data/food-101/images'\n",
        "foods_sorted = sorted(os.listdir(data_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "40MUwHwtAn5f"
      },
      "outputs": [],
      "source": [
        "# Helper method to split dataset into train and test folders\n",
        "def prepare_data(filepath, src,dest):\n",
        "  classes_images = defaultdict(list)\n",
        "  with open(filepath, 'r') as txt:\n",
        "      paths = [read.strip() for read in txt.readlines()]\n",
        "      for p in paths:\n",
        "        food = p.split('/')\n",
        "        classes_images[food[0]].append(food[1] + '.jpg')\n",
        "\n",
        "  for food in classes_images.keys():\n",
        "    print(\"\\nCopying images into \",food)\n",
        "    if not os.path.exists(os.path.join(dest,food)):\n",
        "      os.makedirs(os.path.join(dest,food))\n",
        "    for i in classes_images[food]:\n",
        "      copy(os.path.join(src,food,i), os.path.join(dest,food,i))\n",
        "  print(\"Copying Done!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtY8IxaBAqIr",
        "outputId": "9b3cbc22-61f0-4558-f9a5-d34c9e5ea11e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/food-101\n"
          ]
        }
      ],
      "source": [
        "%cd food-101/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "q60KW4w4Asim",
        "outputId": "76e562af-bcd4-499d-8f7c-4d30903c4c5b"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/food-101/meta/train.txt'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-c889eaaf295d>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/food-101/meta/train.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/food-101/images'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-2463a5ce7dfa>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(filepath, src, dest)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mclasses_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/food-101/meta/train.txt'"
          ]
        }
      ],
      "source": [
        "prepare_data('/content/food-101/meta/train.txt', '/content/food-101/images', 'train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4vbemxsAyn6"
      },
      "outputs": [],
      "source": [
        "prepare_data('/content/food-101/meta/test.txt', '/content/food-101/images', 'test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL4A3S4UA1Iv"
      },
      "outputs": [],
      "source": [
        "# Check how many files are in the train folder\n",
        "print(\"Total number of samples in train folder\")\n",
        "!find train -type d -or -type f -printf '.' | wc -c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "116G90m9A6yo"
      },
      "outputs": [],
      "source": [
        "# Check how many files are in the test folder\n",
        "print(\"Total number of samples in test folder\")\n",
        "!find test -type d -or -type f -printf '.' | wc -c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMvVPJh8BG8j"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "num_classes = 101\n",
        "img_width, img_height = 224, 224\n",
        "train_dir = '/content/food-101/train'\n",
        "val_dir = '/content/food-101/test'\n",
        "nb_train_samples = 75750\n",
        "nb_validation_samples = 25250\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 654
        },
        "id": "F3G9-LVwL2fG",
        "outputId": "5307deca-57bc-47c0-fa4d-e6e5d7167a6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 75750 images belonging to 101 classes.\n",
            "Found 25250 images belonging to 101 classes.\n",
            "Epoch 1/2\n",
            "2368/2368 [==============================] - 953s 368ms/step - loss: 2.5201 - sparse_categorical_accuracy: 0.3830 - val_loss: 6.1067 - val_sparse_categorical_accuracy: 0.0286\n",
            "Epoch 2/2\n",
            "2368/2368 [==============================] - 858s 362ms/step - loss: 1.7343 - sparse_categorical_accuracy: 0.5525 - val_loss: 4.4710 - val_sparse_categorical_accuracy: 0.1181\n",
            "790/790 [==============================] - 90s 114ms/step - loss: 4.4710 - sparse_categorical_accuracy: 0.1181\n",
            "Validation Loss: 4.471022129058838\n",
            "Validation Accuracy: 0.11805940419435501\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "ename": "OSError",
          "evalue": "[Errno 95] Unable to create file (unable to open file: name = '/content/gdrive/efficientnetv2_food101_model.h5', errno = 95, error message = 'Operation not supported', flags = 13, o_flags = 242)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-1042ea0055dd>\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/gdrive/efficientnetv2_food101_model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    565\u001b[0m                                  \u001b[0mfs_persist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_persist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs_threshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfs_threshold\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                                  fs_page_size=fs_page_size)\n\u001b[0;32m--> 567\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0;31m# Open in append mode (read/write).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 95] Unable to create file (unable to open file: name = '/content/gdrive/efficientnetv2_food101_model.h5', errno = 95, error message = 'Operation not supported', flags = 13, o_flags = 242)"
          ]
        }
      ],
      "source": [
        "\n",
        "BATCH_SIZE = 64\n",
        "IMG_SIZE = (224, 224)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='sparse'\n",
        ")\n",
        "\n",
        "base_model = EfficientNetV2S(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
        "base_model.trainable = True\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer=AdamW(),\n",
        "              loss=SparseCategoricalCrossentropy(),\n",
        "              metrics=SparseCategoricalAccuracy())\n",
        "\n",
        "epoch = 2\n",
        "history = model.fit(train_generator, validation_data=val_generator, epochs=epoch)\n",
        "\n",
        "val_loss, val_acc = model.evaluate(val_generator)\n",
        "print(\"Validation Loss:\", val_loss)\n",
        "print(\"Validation Accuracy:\", val_acc)\n",
        "\n",
        "\n",
        "\n",
        "model.save(\"/content/gdrive/efficientnetv2_food101_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1P3dpjZfp_Tv",
        "outputId": "59091590-1d88-4331-d830-2e123ec51d90"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`efficientnetv2-s_input` is not a valid tf.function parameter name. Sanitizing to `efficientnetv2_s_input`.\n",
            "WARNING:absl:`efficientnetv2-s_input` is not a valid tf.function parameter name. Sanitizing to `efficientnetv2_s_input`.\n",
            "WARNING:absl:`efficientnetv2-s_input` is not a valid tf.function parameter name. Sanitizing to `efficientnetv2_s_input`.\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-4G_E3fBLDF"
      },
      "source": [
        "Load model and print specifications\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "WafOkCOrquHL"
      },
      "outputs": [],
      "source": [
        "model.save('/content/trained_food101.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "5z_smRncBMHj"
      },
      "outputs": [],
      "source": [
        "#EfficientNetV2L = load_model('/content/gdrive/')\n",
        "EfficientNetV2S = load_model('/content/trained_food101.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kv0OZRBrBTYZ"
      },
      "outputs": [],
      "source": [
        "def print_model_details(model):\n",
        "    def namestr(obj, namespace):\n",
        "        return [name for name in namespace if namespace[name] is obj]\n",
        "    print(\"==========================================================\")\n",
        "    print(\"Model Name: \", namestr(model, globals()))\n",
        "    print(\"Number of Layers: \", len(model.layers))\n",
        "    print(\"Number of Parameters: \", format(model.count_params(), ',d'))\n",
        "    print(\"==========================================================\\n\")\n",
        "\n",
        "\n",
        "# print_model_details(EfficientNetV2L)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "1ecDtz4sBeGt"
      },
      "outputs": [],
      "source": [
        "# Print training, test accuracy and loss of the model\n",
        "def model_eval(model, train, val):\n",
        "    # evaluate the model\n",
        "    train_loss, train_acc = model.evaluate(train, verbose=1)\n",
        "    val_loss, val_acc = model.evaluate(val, verbose=1)\n",
        "    print('Train loss:', train_loss)\n",
        "    print('Train accuracy:', train_acc)\n",
        "    print('Validation loss:', val_loss)\n",
        "    print('Validation accuracy:', val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUs7IPTfBaEV"
      },
      "outputs": [],
      "source": [
        "# model_eval(EfficientNetV2L, train_generator, val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "VE-pfOtPBWn_"
      },
      "outputs": [],
      "source": [
        "# Print training, test accuracy and loss of the model\n",
        "def model_eval(model, train, val):\n",
        "    # evaluate the model\n",
        "    train_loss, train_acc = model.evaluate(train, verbose=1)\n",
        "    val_loss, val_acc = model.evaluate(val, verbose=1)\n",
        "    print('Train loss:', train_loss)\n",
        "    print('Train accuracy:', train_acc)\n",
        "    print('Validation loss:', val_loss)\n",
        "    print('Validation accuracy:', val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygsG_ReuBimr",
        "outputId": "acbfd6e2-c534-4577-a027-a4e2ba8aeb71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==========================================================\n",
            "Model Name:  ['EfficientNetV2S']\n",
            "Number of Layers:  3\n",
            "Number of Parameters:  20,460,741\n",
            "==========================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_model_details(EfficientNetV2S)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLfMqyEUBkzF",
        "outputId": "ec24120f-4d1c-477a-cb17-ffe4f9ca2a96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2368/2368 [==============================] - 679s 285ms/step - loss: 4.5751 - sparse_categorical_accuracy: 0.0960\n",
            "790/790 [==============================] - 113s 142ms/step - loss: 4.4710 - sparse_categorical_accuracy: 0.1181\n",
            "Train loss: 4.575064659118652\n",
            "Train accuracy: 0.09600000083446503\n",
            "Validation loss: 4.471022605895996\n",
            "Validation accuracy: 0.11805940419435501\n"
          ]
        }
      ],
      "source": [
        "model_eval(EfficientNetV2S, train_generator, val_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXr_JMJAtlcN",
        "outputId": "df6ac2e9-1924-4e10-d21e-b88a1ecd09a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Class Names:\n",
            "Class index: 0, Class name: apple_pie\n",
            "Class index: 1, Class name: baby_back_ribs\n",
            "Class index: 2, Class name: baklava\n",
            "Class index: 3, Class name: beef_carpaccio\n",
            "Class index: 4, Class name: beef_tartare\n",
            "Class index: 5, Class name: beet_salad\n",
            "Class index: 6, Class name: beignets\n",
            "Class index: 7, Class name: bibimbap\n",
            "Class index: 8, Class name: bread_pudding\n",
            "Class index: 9, Class name: breakfast_burrito\n",
            "Class index: 10, Class name: bruschetta\n",
            "Class index: 11, Class name: caesar_salad\n",
            "Class index: 12, Class name: cannoli\n",
            "Class index: 13, Class name: caprese_salad\n",
            "Class index: 14, Class name: carrot_cake\n",
            "Class index: 15, Class name: ceviche\n",
            "Class index: 16, Class name: cheese_plate\n",
            "Class index: 17, Class name: cheesecake\n",
            "Class index: 18, Class name: chicken_curry\n",
            "Class index: 19, Class name: chicken_quesadilla\n",
            "Class index: 20, Class name: chicken_wings\n",
            "Class index: 21, Class name: chocolate_cake\n",
            "Class index: 22, Class name: chocolate_mousse\n",
            "Class index: 23, Class name: churros\n",
            "Class index: 24, Class name: clam_chowder\n",
            "Class index: 25, Class name: club_sandwich\n",
            "Class index: 26, Class name: crab_cakes\n",
            "Class index: 27, Class name: creme_brulee\n",
            "Class index: 28, Class name: croque_madame\n",
            "Class index: 29, Class name: cup_cakes\n",
            "Class index: 30, Class name: deviled_eggs\n",
            "Class index: 31, Class name: donuts\n",
            "Class index: 32, Class name: dumplings\n",
            "Class index: 33, Class name: edamame\n",
            "Class index: 34, Class name: eggs_benedict\n",
            "Class index: 35, Class name: escargots\n",
            "Class index: 36, Class name: falafel\n",
            "Class index: 37, Class name: filet_mignon\n",
            "Class index: 38, Class name: fish_and_chips\n",
            "Class index: 39, Class name: foie_gras\n",
            "Class index: 40, Class name: french_fries\n",
            "Class index: 41, Class name: french_onion_soup\n",
            "Class index: 42, Class name: french_toast\n",
            "Class index: 43, Class name: fried_calamari\n",
            "Class index: 44, Class name: fried_rice\n",
            "Class index: 45, Class name: frozen_yogurt\n",
            "Class index: 46, Class name: garlic_bread\n",
            "Class index: 47, Class name: gnocchi\n",
            "Class index: 48, Class name: greek_salad\n",
            "Class index: 49, Class name: grilled_cheese_sandwich\n",
            "Class index: 50, Class name: grilled_salmon\n",
            "Class index: 51, Class name: guacamole\n",
            "Class index: 52, Class name: gyoza\n",
            "Class index: 53, Class name: hamburger\n",
            "Class index: 54, Class name: hot_and_sour_soup\n",
            "Class index: 55, Class name: hot_dog\n",
            "Class index: 56, Class name: huevos_rancheros\n",
            "Class index: 57, Class name: hummus\n",
            "Class index: 58, Class name: ice_cream\n",
            "Class index: 59, Class name: lasagna\n",
            "Class index: 60, Class name: lobster_bisque\n",
            "Class index: 61, Class name: lobster_roll_sandwich\n",
            "Class index: 62, Class name: macaroni_and_cheese\n",
            "Class index: 63, Class name: macarons\n",
            "Class index: 64, Class name: miso_soup\n",
            "Class index: 65, Class name: mussels\n",
            "Class index: 66, Class name: nachos\n",
            "Class index: 67, Class name: omelette\n",
            "Class index: 68, Class name: onion_rings\n",
            "Class index: 69, Class name: oysters\n",
            "Class index: 70, Class name: pad_thai\n",
            "Class index: 71, Class name: paella\n",
            "Class index: 72, Class name: pancakes\n",
            "Class index: 73, Class name: panna_cotta\n",
            "Class index: 74, Class name: peking_duck\n",
            "Class index: 75, Class name: pho\n",
            "Class index: 76, Class name: pizza\n",
            "Class index: 77, Class name: pork_chop\n",
            "Class index: 78, Class name: poutine\n",
            "Class index: 79, Class name: prime_rib\n",
            "Class index: 80, Class name: pulled_pork_sandwich\n",
            "Class index: 81, Class name: ramen\n",
            "Class index: 82, Class name: ravioli\n",
            "Class index: 83, Class name: red_velvet_cake\n",
            "Class index: 84, Class name: risotto\n",
            "Class index: 85, Class name: samosa\n",
            "Class index: 86, Class name: sashimi\n",
            "Class index: 87, Class name: scallops\n",
            "Class index: 88, Class name: seaweed_salad\n",
            "Class index: 89, Class name: shrimp_and_grits\n",
            "Class index: 90, Class name: spaghetti_bolognese\n",
            "Class index: 91, Class name: spaghetti_carbonara\n",
            "Class index: 92, Class name: spring_rolls\n",
            "Class index: 93, Class name: steak\n",
            "Class index: 94, Class name: strawberry_shortcake\n",
            "Class index: 95, Class name: sushi\n",
            "Class index: 96, Class name: tacos\n",
            "Class index: 97, Class name: takoyaki\n",
            "Class index: 98, Class name: tiramisu\n",
            "Class index: 99, Class name: tuna_tartare\n",
            "Class index: 100, Class name: waffles\n"
          ]
        }
      ],
      "source": [
        "# Get the class indices from the train generator\n",
        "class_indices=train_generator.class_indices\n",
        "# Invert the dictionary to map indices to class names\n",
        "class_names={v: k for k, v in class_indices.items()}\n",
        "# Print the class names\n",
        "print(\"Class Names:\")\n",
        "for idx, class_name in class_names.items():\n",
        "    print(f\"Class index: {idx}, Class name: {class_name}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Id41G2GBvoLI",
        "outputId": "31088a52-8789-43e1-8be0-eabfd964e839"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'apple_pie', 1: 'baby_back_ribs', 2: 'baklava', 3: 'beef_carpaccio', 4: 'beef_tartare', 5: 'beet_salad', 6: 'beignets', 7: 'bibimbap', 8: 'bread_pudding', 9: 'breakfast_burrito', 10: 'bruschetta', 11: 'caesar_salad', 12: 'cannoli', 13: 'caprese_salad', 14: 'carrot_cake', 15: 'ceviche', 16: 'cheese_plate', 17: 'cheesecake', 18: 'chicken_curry', 19: 'chicken_quesadilla', 20: 'chicken_wings', 21: 'chocolate_cake', 22: 'chocolate_mousse', 23: 'churros', 24: 'clam_chowder', 25: 'club_sandwich', 26: 'crab_cakes', 27: 'creme_brulee', 28: 'croque_madame', 29: 'cup_cakes', 30: 'deviled_eggs', 31: 'donuts', 32: 'dumplings', 33: 'edamame', 34: 'eggs_benedict', 35: 'escargots', 36: 'falafel', 37: 'filet_mignon', 38: 'fish_and_chips', 39: 'foie_gras', 40: 'french_fries', 41: 'french_onion_soup', 42: 'french_toast', 43: 'fried_calamari', 44: 'fried_rice', 45: 'frozen_yogurt', 46: 'garlic_bread', 47: 'gnocchi', 48: 'greek_salad', 49: 'grilled_cheese_sandwich', 50: 'grilled_salmon', 51: 'guacamole', 52: 'gyoza', 53: 'hamburger', 54: 'hot_and_sour_soup', 55: 'hot_dog', 56: 'huevos_rancheros', 57: 'hummus', 58: 'ice_cream', 59: 'lasagna', 60: 'lobster_bisque', 61: 'lobster_roll_sandwich', 62: 'macaroni_and_cheese', 63: 'macarons', 64: 'miso_soup', 65: 'mussels', 66: 'nachos', 67: 'omelette', 68: 'onion_rings', 69: 'oysters', 70: 'pad_thai', 71: 'paella', 72: 'pancakes', 73: 'panna_cotta', 74: 'peking_duck', 75: 'pho', 76: 'pizza', 77: 'pork_chop', 78: 'poutine', 79: 'prime_rib', 80: 'pulled_pork_sandwich', 81: 'ramen', 82: 'ravioli', 83: 'red_velvet_cake', 84: 'risotto', 85: 'samosa', 86: 'sashimi', 87: 'scallops', 88: 'seaweed_salad', 89: 'shrimp_and_grits', 90: 'spaghetti_bolognese', 91: 'spaghetti_carbonara', 92: 'spring_rolls', 93: 'steak', 94: 'strawberry_shortcake', 95: 'sushi', 96: 'tacos', 97: 'takoyaki', 98: 'tiramisu', 99: 'tuna_tartare', 100: 'waffles'}\n"
          ]
        }
      ],
      "source": [
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "mHbWyS2Kv3U9"
      },
      "outputs": [],
      "source": [
        "class_names = list(train_generator.class_indices.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsdkVSuXwUwp",
        "outputId": "d09c0f3a-cdfe-4fec-c272-1f8b36b47bf3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n"
          ]
        }
      ],
      "source": [
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I4gJEKo06CNr"
      },
      "source": [
        "Install requirements and libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQKymgh77LEo"
      },
      "outputs": [],
      "source": [
        "#!pip3 install pytorch_lightning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tux7sPGG7U2C"
      },
      "source": [
        "Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dDwAQrcVlZE2"
      },
      "outputs": [],
      "source": [
        "#!pip3 install requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p02MSaHYhKlT"
      },
      "source": [
        "Library importing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BfCsAaqi_WNX"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.image as img\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "%matplotlib inline\n",
        "from collections import defaultdict\n",
        "import collections\n",
        "\n",
        "from shutil import copy\n",
        "from shutil import copytree, rmtree\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from tensorflow.keras import models\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.xception import Xception\n",
        "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2S, EfficientNetV2L\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, AveragePooling2D\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image as image_utils\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h3YkATq_0UE",
        "outputId": "725f111d-86cc-4da6-94b4-b4c06b4a0689"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Mar 22 06:07:57 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   69C    P0              31W /  70W |  14093MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIECvQBqAHRZ"
      },
      "source": [
        "Load trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynPmsVog_1rF"
      },
      "outputs": [],
      "source": [
        "# Loading the best saved models to make predictions\n",
        "K.clear_session()\n",
        "# model_best = load_model('models/EfficientNetV2S/EfficientNetV2S.hdf5', compile=False)\n",
        "# model_best = load_model('models/EfficientNetV2L/EfficientNetV2L.hdf5', compile=False)\n",
        "model_best = load_model('/content/gdrive/Othercomputers/MyLaptop/thesis2024/efficientnetv2/EfficientNetV2L.hdf5', compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3s0QlLwAGeE"
      },
      "outputs": [],
      "source": [
        "# Foods sorted\n",
        "# data_dir = \"/workspace/persistent/food-101/images\" # This is for DSRI workspace path\n",
        "\n",
        "data_dir = \"/content/food-101/images\" # This is for local path\n",
        "\n",
        "foods_sorted = sorted(os.listdir(data_dir))\n",
        "\n",
        "\n",
        "# foods_sorted = ['apple_pie','pizza','omelette']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "0LUhHBCyBzIb"
      },
      "outputs": [],
      "source": [
        "def pick_n_random_classes(n):\n",
        "  food_list = []\n",
        "  random_food_indices = random.sample(range(len(foods_sorted)),n) # We are picking n random food classes\n",
        "  for i in random_food_indices:\n",
        "    food_list.append(foods_sorted[i])\n",
        "  food_list.sort()\n",
        "  return food_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YnmvAPawB0b_"
      },
      "outputs": [],
      "source": [
        "food_list = pick_n_random_classes(101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLAv0IrBB10v",
        "outputId": "22a18bae-fbf4-4f51-9968-9d8e28d8dc9f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['apple_pie',\n",
              " 'baby_back_ribs',\n",
              " 'baklava',\n",
              " 'beef_carpaccio',\n",
              " 'beef_tartare',\n",
              " 'beet_salad',\n",
              " 'beignets',\n",
              " 'bibimbap',\n",
              " 'bread_pudding',\n",
              " 'breakfast_burrito',\n",
              " 'bruschetta',\n",
              " 'caesar_salad',\n",
              " 'cannoli',\n",
              " 'caprese_salad',\n",
              " 'carrot_cake',\n",
              " 'ceviche',\n",
              " 'cheese_plate',\n",
              " 'cheesecake',\n",
              " 'chicken_curry',\n",
              " 'chicken_quesadilla',\n",
              " 'chicken_wings',\n",
              " 'chocolate_cake',\n",
              " 'chocolate_mousse',\n",
              " 'churros',\n",
              " 'clam_chowder',\n",
              " 'club_sandwich',\n",
              " 'crab_cakes',\n",
              " 'creme_brulee',\n",
              " 'croque_madame',\n",
              " 'cup_cakes',\n",
              " 'deviled_eggs',\n",
              " 'donuts',\n",
              " 'dumplings',\n",
              " 'edamame',\n",
              " 'eggs_benedict',\n",
              " 'escargots',\n",
              " 'falafel',\n",
              " 'filet_mignon',\n",
              " 'fish_and_chips',\n",
              " 'foie_gras',\n",
              " 'french_fries',\n",
              " 'french_onion_soup',\n",
              " 'french_toast',\n",
              " 'fried_calamari',\n",
              " 'fried_rice',\n",
              " 'frozen_yogurt',\n",
              " 'garlic_bread',\n",
              " 'gnocchi',\n",
              " 'greek_salad',\n",
              " 'grilled_cheese_sandwich',\n",
              " 'grilled_salmon',\n",
              " 'guacamole',\n",
              " 'gyoza',\n",
              " 'hamburger',\n",
              " 'hot_and_sour_soup',\n",
              " 'hot_dog',\n",
              " 'huevos_rancheros',\n",
              " 'hummus',\n",
              " 'ice_cream',\n",
              " 'lasagna',\n",
              " 'lobster_bisque',\n",
              " 'lobster_roll_sandwich',\n",
              " 'macaroni_and_cheese',\n",
              " 'macarons',\n",
              " 'miso_soup',\n",
              " 'mussels',\n",
              " 'nachos',\n",
              " 'omelette',\n",
              " 'onion_rings',\n",
              " 'oysters',\n",
              " 'pad_thai',\n",
              " 'paella',\n",
              " 'pancakes',\n",
              " 'panna_cotta',\n",
              " 'peking_duck',\n",
              " 'pho',\n",
              " 'pizza',\n",
              " 'pork_chop',\n",
              " 'poutine',\n",
              " 'prime_rib',\n",
              " 'pulled_pork_sandwich',\n",
              " 'ramen',\n",
              " 'ravioli',\n",
              " 'red_velvet_cake',\n",
              " 'risotto',\n",
              " 'samosa',\n",
              " 'sashimi',\n",
              " 'scallops',\n",
              " 'seaweed_salad',\n",
              " 'shrimp_and_grits',\n",
              " 'spaghetti_bolognese',\n",
              " 'spaghetti_carbonara',\n",
              " 'spring_rolls',\n",
              " 'steak',\n",
              " 'strawberry_shortcake',\n",
              " 'sushi',\n",
              " 'tacos',\n",
              " 'takoyaki',\n",
              " 'tiramisu',\n",
              " 'tuna_tartare',\n",
              " 'waffles']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "food_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "9VO8NcymB3ir"
      },
      "outputs": [],
      "source": [
        "def predict_class(model, images, show = True):\n",
        "  for img in images:\n",
        "    img = image.load_img(img, target_size=(299, 299))\n",
        "    img = image.img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img /= 255.\n",
        "\n",
        "    pred = model.predict(img)\n",
        "    index = np.argmax(pred)\n",
        "    food_list.sort()\n",
        "    pred_value = food_list[index]\n",
        "    if show:\n",
        "        plt.imshow(img[0])\n",
        "        plt.axis('off')\n",
        "        plt.title(pred_value)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlvGhyXKB5yT"
      },
      "outputs": [],
      "source": [
        "images = []\n",
        "# images.append('test_images/Apple.jpg')\n",
        "# images.append('test_images/applepie.jpg')\n",
        "# images.append('test_images/cupcakes.jpg')\n",
        "# images.append('test_images/springrolls.jpg')\n",
        "# images.append('test_images/samosa.jpg')\n",
        "\n",
        "\n",
        "# images.append('test_images/burger.jpeg')\n",
        "# images.append('test_images/hardburger.jpg')\n",
        "# images.append('test_images/dim1.jpeg')\n",
        "# images.append('test_images/dim2.jpeg')\n",
        "\n",
        "# images.append('test_images/leo.jpg')\n",
        "\n",
        "\n",
        "images.append('test_images/steak.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSXkiPEzCJsp"
      },
      "outputs": [],
      "source": [
        "images.append('test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6uvwbpG3tsT"
      },
      "outputs": [],
      "source": [
        "model=load_model('/content/trained_food101.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpS5KkdsyhS7",
        "outputId": "72ed1f67-dca2-42d3-e149-445e8262a7c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image as image_utils\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    image=image_utils.load_img(image_path,target_size=(224,224))\n",
        "    image=image_utils.img_to_array(image)\n",
        "    image=np.expand_dims(image,axis=0)\n",
        "    image=tf.keras.applications.efficientnet.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "# Load and preprocess image\n",
        "image = load_and_preprocess_image('/content/test2.jpg')\n",
        "\n",
        "# Make a prediction\n",
        "preds = model.predict(image)\n",
        "\n",
        "# Get the class with the highest probability\n",
        "predicted_class = np.argmax(preds[0])\n",
        "\n",
        "# Get the class name\n",
        "class_names = ['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']  # replace with your actual class names\n",
        "predicted_class_name = class_names[predicted_class]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CX4j4eiu3gB_",
        "outputId": "63b932c4-f032-4a53-b79d-c3ee984aace4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 35ms/step\n",
            "bibimbap\n"
          ]
        }
      ],
      "source": [
        "model.predict(image)\n",
        "print(predicted_class_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LeMxD0qEx0lP",
        "outputId": "ade4003e-9413-4455-ec82-963360003920"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "app_id=\"c1139736\"\n",
        "app_key=\"4f7b833a6252f3291c794f3b37f32300\"\n",
        "food_item=predicted_class_name\n",
        "def get_recipe(app_id, app_key, food_item):\n",
        "    # API endpoint\n",
        "    url = \"https://api.edamam.com/api/recipes/v2\"\n",
        "\n",
        "    # API parameters\n",
        "    params = {\n",
        "        \"type\":\"public\",\n",
        "        \"q\":food_item,\n",
        "        \"app_id\": app_id,\n",
        "        \"app_key\": app_key,\n",
        "        \"field\": \"label,image,ingredients,calories,totalTime\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    # # Check if the request was successful\n",
        "    # if response.status_code == 200:\n",
        "    #     # Return the response\n",
        "    #     return response.json()\n",
        "    # else:\n",
        "    #     # Return None if the request was not successful\n",
        "    #     return None\n",
        "\n",
        "# Example usage\n",
        "recipe = get_recipe(app_id,app_key,\"bibimbap\")\n",
        "print(recipe)\n",
        "if recipe is not None:\n",
        "    recipe_label = recipe['hits'][0]['recipe']['label']\n",
        "    recipe_image = recipe['hits'][0]['recipe']['image']\n",
        "    recipe_ingredients = recipe['hits'][0]['recipe']['ingredientLines']\n",
        "\n",
        "    print(f\"Recipe label: {recipe_label}\")\n",
        "    print(f\"Recipe image: {recipe_image}\")\n",
        "    print(\"Recipe ingredients:\")\n",
        "    for ingredient in recipe_ingredients:\n",
        "        print(ingredient)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gMzLVh5CJOL"
      },
      "outputs": [],
      "source": [
        "# show images\n",
        "predict_class(model_best, images, show = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1fVTQaNCNf6"
      },
      "outputs": [],
      "source": [
        "wrong = []\n",
        "wrong.append('test_images/hardburger.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ngm7E4qjCO3w"
      },
      "outputs": [],
      "source": [
        "predict_class(model_best, wrong, show = True)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
